# 09. Monitoring <!-- omit in toc -->

# 1. Monitoring
> [Grafana Monitoring](https://docs.flagger.app/usage/monitoring)

El siguiente monitoreo no es una solución completa para Kubernetes, sino es una visualización de métricas para efectos de la automatización de despliegues.

```

helm install grafana grafana/grafana \
  --namespace ingress-nginx \
	--set adminPassword="admin" \
	--set service.type=NodePort

kubectl get svc -n ingress-nginx
```
## 1.1. Ingresar a Grafana
- Agregar el Datasource:
```
url=http://flagger-prometheus:9090
```
- Save & Test

## 1.2. Importar el dashboard: 12575
Este ID importa un dashboard de Nginx para Kubernetes
> [Nginx Dashboard](https://grafana.com/grafana/dashboards/12575-kubernetes-ingress-controller-dashboard/)

## 1.3. Explorar mas dashboards:
> [Grafana Dahsboards](https://grafana.com/grafana/dashboards/?search=kubernetes)

Ejemplos:
- 741
- 19972
- 315

## 1.4. Crear un dashboard personalizado

### 1.4.1. Agregar la métrica de Prometheus
1. Métrica general
nginx_ingress_controller_requests
2. Rate + interval
rate(nginx_ingress_controller_requests[$__rate_interval])

### 1.4.2. Cambiar las configuraciones
Type: Time series

last 15 min

Legend: {{service}} ({{status}})

name: POD's Request/s

line width: 4

fill opacity: 60

Gradient Mode: Opacity

Unit: Throughput - request/sec

thresholds: red: 300

show thresholds: as lines (dashed)

### 1.4.3. Aplicar cambios
Apply + Save

### 1.4.4. Agregar una variable
Agregar Variables: Config
- Type: Query
- Name: service
- Label: Service
- Query Type: Label values
  - label: service
- Apply & Save Dashboard



### 1.4.5. Mostrar acumulado
sum(rate(nginx_ingress_controller_requests{service=~"$service"}[$__rate_interval]))by (service)

type: Stat


# 2. Enviar tráfico y visualizar
Frecuencia: 5s

# 3. Mas información
> [Grafana Kubernetes](https://grafana.com/docs/grafana-cloud/monitor-infrastructure/kubernetes-monitoring/respond-to-alerts/?pg=solutions-kubernetes-monitor&plcmt=metrics-alerts)

# 4. Operación básica
## 4.1. Modificar el endpoint del cluster para aceptar conexiones externas
```
sudo nano /etc/systemd/system/k3s.service
```
Agregar --tls-san <PUBLIC_IP>
```
ExecStart=/usr/local/bin/k3s \
    server --tls-san <PUBLIC_IP>
```

# 5. Reiniciar el cluster
```
sudo systemctl daemon-reload
sudo systemctl restart k3s
```

# 6. Copiar el Kubeconfig
```
cat ~/.kube.config
```
## 6.1. Agregarle la IP al Kubeconfig
```
server: https://<PUBLIC_IP>:6443
```

# 7. Instalar y configurar Lens
> [LENS](https://k8slens.dev/)


# 8. Logging
> [Loki](https://grafana.com/docs/loki/latest/setup/install/helm/install-monolithic/)

```
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
```

## 8.1. values.yaml
```yaml
deploymentMode: SingleBinary
loki:
  auth_enabled: false
  commonConfig:
    replication_factor: 1
  storage:
    type: 'filesystem'
  schemaConfig:
    configs:
    - from: "2024-01-01"
      store: tsdb
      index:
        prefix: loki_index_
        period: 24h
      object_store: filesystem # we're storing on filesystem so there's no real persistence here.
      schema: v13
singleBinary:
  replicas: 1
read:
  replicas: 0
backend:
  replicas: 0
write:
  replicas: 0
```

```
helm install --values values.yml --namespace ingress-nginx loki grafana/loki
```

# 9. Agregar extractor de logs

### 9.0.1. values-fluentbit.yaml

*** Cambiar FLUENT_LOKI_URL ***
```yaml
image:
  # Here we use the Docker image which has the plugin installed
  repository: grafana/fluent-bit-plugin-loki
  tag: main-e2ed1c0

args:
  - "-e"
  - "/fluent-bit/bin/out_grafana_loki.so"
  - --workdir=/fluent-bit/etc
  - --config=/fluent-bit/etc/conf/fluent-bit.conf

env:
  - name: FLUENT_LOKI_URL
    value: http://loki-gateway.ingress-nginx.svc.cluster.local/loki/api/v1/push
config:
  inputs: |
    [INPUT]
        Name tail
        Tag kube.*
        Path /var/log/containers/*.log
        # Be aware that local clusters like docker-desktop or kind use the docker log format and not the cri (https://docs.fluentbit.io/manual/installation/kubernetes#container-runtime-interface-cri-parser)
        multiline.parser docker, cri
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On

  outputs: |
    [Output]
        Name grafana-loki
        Match kube.*
        Url ${FLUENT_LOKI_URL}
        Labels {job="fluent-bit"}
        LabelKeys level,app # this sets the values for actual Loki streams and the other labels are converted to structured_metadata https://grafana.com/docs/loki/<LOKI_VERSION>/get-started/labels/structured-metadata/
        BatchWait 1helm install fluent-bit fluent/fluent-bit --namespace ingress-nginx -f values-f
        BatchSize 1001024
        LineFormat json
        LogLevel info
        AutoKubernetesLabels true
```

```
helm repo add fluent https://fluent.github.io/helm-charts
helm repo update
helm install fluent-bit fluent/fluent-bit --namespace ingress-nginx -f values-fluentbit.yaml

```


## 9.1. Grafana Datasource: Loki
```
http://loki-gateway.ingress-nginx.svc.cluster.local/
```

## 9.2. Opción menu: Explore, seleccionar el data source Loki

## 9.3. Label browser: service_name
### 9.3.1. Run query

